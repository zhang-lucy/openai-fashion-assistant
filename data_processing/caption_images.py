import pandas as pd
from transformers import BlipProcessor, BlipForConditionalGeneration
from PIL import Image
import requests
import os
import json

# Load once at the top-level to avoid re-downloading models
processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained(
    "Salesforce/blip-image-captioning-base"
)


def generate_caption(image_url: str) -> str:
    """Given an image URL, returns a caption generated by BLIP."""
    try:
        image = Image.open(requests.get(image_url, stream=True).raw).convert("RGB")
        inputs = processor(images=image, return_tensors="pt")
        output = model.generate(**inputs)
        caption = processor.decode(output[0], skip_special_tokens=True)
        return caption
    except Exception as e:
        return f"Error processing image: {e}"


def process_images(
    df: pd.DataFrame, start_index: int = 0, output_dir: str = "image_captions"
):
    os.makedirs(output_dir, exist_ok=True)

    for i, row in df.iloc[start_index : start_index + 100000].iterrows():
        image_url = row["image_url"]
        primary_keys = row["primary_keys"]

        caption = generate_caption(image_url)

        result = {
            "image_url": image_url,
            "primary_keys": primary_keys,
            "caption": caption,
        }

        output_path = os.path.join(output_dir, f"caption_{i}.json")
        with open(output_path, "w") as f:
            json.dump(result, f, indent=2)

        print(f"[{i}] Wrote caption to {output_path}")


if __name__ == "__main__":
    file_path = "image_urls.csv"
    df = pd.read_csv(file_path)
    process_images(df, start_index=200000)
